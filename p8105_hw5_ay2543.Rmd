---
title: "p8105_hw5_ay2543"
author: "Amy Yeung"
date: "2022-11-09"
output: github_document
---

```{r, include = FALSE}
library(tidyverse)
library(purrr)
library(patchwork)
```

## Problem 1

The code chunk below imports the data in individual spreadsheets contained in `./data/zip_data/`. To do this, I create a dataframe that includes the list of all files in that directory and the complete path to each file. As a next step, I `map` over paths and import data using the `read_csv` function. Finally, I `unnest` the result of `map`.

```{r}
full_df = 
  tibble(
    files = list.files("data/"),
    path = str_c("data/", files)
  ) %>% 
  mutate(data = map(path, read_csv)) %>% 
  unnest()
```

The result of the previous code chunk isn't tidy -- data are wide rather than long, and some important variables are included as parts of others. The code chunk below tides the data using string manipulations on the file, converting from wide to long, and selecting relevant variables. 

```{r}
tidy_df = 
  full_df %>% 
  mutate(
    files = str_replace(files, ".csv", ""),
    group = str_sub(files, 1, 3)) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "outcome",
    names_prefix = "week_") %>% 
  mutate(week = as.numeric(week)) %>% 
  select(group, subj = files, week, outcome)
```

Finally, the code chunk below creates a plot showing individual data, faceted by group. 

```{r}
tidy_df %>% 
  ggplot(aes(x = week, y = outcome, group = subj, color = group)) + 
  geom_point() + 
  geom_path() + 
  facet_grid(~group)
```

This plot suggests high within-subject correlation -- subjects who start above average end up above average, and those that start below average end up below average. Subjects in the control group generally don't change over time, but those in the experiment group increase their outcome in a roughly linear way. 





## Problem 2

First, import the raw homicide dataset:

```{r, message = FALSE}
homicide = read_csv("homicide-data.csv")
```

The raw data has **`r nrow(homicide)` observations and `r ncol(homicide)` variables**.

The variable names are *`r colnames(homicide)`*.

Next, do some cleaning:

```{r}
homicide_summ = homicide %>% 
  mutate(city_state = str_c(city, ", ", state)) %>% 
  group_by(city_state, disposition) %>% 
  summarize(n_homicides = n()) %>% 
  pivot_wider(names_from = disposition,
              values_from = n_homicides) %>% 
  janitor::clean_names() %>% 
  mutate(
    n_homicides = sum(closed_by_arrest, closed_without_arrest, open_no_arrest, na.rm = TRUE),
    n_unsolved = sum(closed_without_arrest, open_no_arrest, na.rm = TRUE)
  ) %>% 
  select(city_state, n_homicides, n_unsolved)


```


Now, do a `prop.test` on Baltimore, MD:
```{r}
prop_baltimore = prop.test(x = homicide_summ %>% 
                             filter(city_state == "Baltimore, MD") %>% 
                             pull(n_unsolved), 
                           n = homicide_summ %>% 
                             filter(city_state == "Baltimore, MD") %>% 
                             pull(n_homicides)) %>% broom::tidy() %>% select(estimate, conf.low, conf.high)

prop_baltimore

```

Now run `prop.test` for each of the cities in the dataset, and extract both the proportion of unsolved homicides and the confidence interval for each into a tidy dataframe.

```{r}


homicide_prop = homicide_summ %>% 
  mutate( 
    prop_test = map2(.x = n_unsolved, .y = n_homicides, ~prop.test(x = .x, n = .y)),
    prop_output = map(.x = prop_test, ~broom::tidy(.x))
    ) %>% 
  unnest(prop_output) %>% 
  select(n_homicides, n_unsolved, estimate, conf.low, conf.high)


```


Finally, create a plot that shows the estimates and CIs for each city with `ggplot()`.

```{r}
homicide_plot = homicide_prop %>% 
  ggplot(aes(x = fct_reorder(city_state, estimate))) +
  geom_point(aes(y = estimate)) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme_classic() +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)
  ) + 
  labs(
    x = "City",
    y = "Proportion of unsolved homicides",
    title = "Proportion of unsolved homicides by city",
    caption = "Tulsa, AL has 1 homicide and 0 unsolved homicides"
  )
```



## Problem 3

First, create a `sim_t_test` function to select the estimate and p-value (using `broom::tidy()`) from a `t.test` of a sample with defined design elements: n=30, σ=5, μ=0. Use a for loop to create 5000 datasets from the function, and use `bind_rows` to combine everything into a dataset.
```{r}
sim_t_test = function(n = 30, mu = 0, sigma = 5) {
sample = rnorm(n, mean = mu, sd = sigma)

test_results = t.test(sample)

test_results %>% 
  broom::tidy() %>% 
  select(estimate, p.value) 
  
}


sim_df = vector("list", 5000)
for (i in 1:5000) {
  sim_df[[i]] = sim_t_test()
}

sim_df = sim_df %>% 
    bind_rows()
  
sim_df


```


Next, create a second `sim_t_murange` function, to conduct the sim_t_test over a range of values of μ, added a variable indicating the power of the test (either rejecting or failing to reject the null hypothesis depending on the p-value), and creating a table of the μ and the simulated t tests (each with 5000 iterations).
```{r}

sim_t_murange = function(murange) {
  sim_mu = vector("list", 5000)
  
  for (i in 1:5000) {
    sim_mu[[i]] = sim_t_test(mu = murange)
  }
  
  sim_mu = sim_mu %>% 
    bind_rows() %>% 
    mutate(null_reject = ifelse(p.value < 0.05, 1, 0))
  
  sim_mu
}

sim_range_df = tibble(
  mu = 0:6,
  t_test = map(.x = 0:6, ~sim_t_murange(murange = .x))
  ) %>% 
  unnest(t_test)

```


Next, look at the association between effect size and power. Use `group_by` and `summarize` to create a separate dataframe with power by μ. The visualize with `ggplot`.
```{r}
power_df = sim_range_df %>% 
  group_by(mu) %>% 
  summarize(prop_reject = sum(null_reject)/5000)

power_plot = power_df %>% 
  ggplot(aes(x = mu, y = prop_reject)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = seq(0, 6, 1)) +
  theme_classic() +
  labs(
    x = "True value of μ",
    y = "Proportion of times the null was rejected (the power of the test)",
    title = "Power of t test by values of μ"
  )

power_plot
```
Here, we can see that as μ increases from 0 to 4, the power increases, and then plateaus as μ goes from 4 to 6, as the power is almost 1. We can conclude that larger effect size is positively associated with the power of the t test.


Then, look at the association between effect size and power. Use `group_by` and `summarize` to create a separate dataframe with effect size and power. Then visualize with `ggplot`.
```{r}
estimate_df = sim_range_df %>% 
  group_by(mu) %>% 
  summarize(mean_muhat = mean(estimate))

estimate_plot = estimate_df %>% 
  ggplot(aes(x = mu, y = mean_muhat)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = seq(0, 6, 1)) + 
  scale_y_continuous(breaks = seq(0, 6, 1)) + 
  theme_classic() +
  labs(
    x = "True value of μ",
    y = "Average estimate of μ̂",
    title = "Average estimate of μ̂ by true value of μ"
  )

estimate_plot
```

Then, look at the association between average estimated μ̂ and μ. Use `group_by` and `summarize` to create a separate dataframe with μ̂ by μ. Then visualize with `ggplot`.
```{r}
estimate_df_reject = sim_range_df %>% 
  filter(null_reject == 1) %>% 
  group_by(mu) %>% 
  summarize(mean_muhat = mean(estimate))

estimate_power_plot = estimate_df_reject %>% 
  ggplot(aes(x = mu, y = mean_muhat)) +
  geom_point(color = "red") +
  geom_line(color = "red") +
  scale_x_continuous(breaks = seq(0, 6, 1)) + 
  scale_y_continuous(breaks = seq(0, 6, 1)) + 
  theme_classic() +
  labs(
    x = "True value of μ",
    y = "Average estimate of μ̂ ",
    title = "Average estimate of μ̂ by true value of μ for samples that rejected null hypothesis"
  )

estimate_power_plot


```


* The sample average of μ̂  across tests for which the null is rejected is not always approximately equal to the true value of μ from μ=1 to μ=4.
* When μ = 0 and when μ≥4, the sample average of μ̂ is approximately equal to the true value of μ

* When μ is small, the power of the t-test is low.
* μ̂ for which the null is rejected is less accurate at lower levels because it is taking the average of less test estimates 
* As μ increases, more estimates are being rejected, so μ̂ is closer to μ.







